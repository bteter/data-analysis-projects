{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1894ccac",
   "metadata": {},
   "source": [
    "# Data Manipulation Studio\n",
    "\n",
    "For this studio, we will revisit the data set from our last studio. If you recall, California farmers were looking for advice on growing pumpkins. We will use the same [pumpkins dataset](https://www.kaggle.com/usda/a-year-of-pumpkin-prices) as provided by the U.S. Department of Agriculture. You may have to clean data in the process of data manipulation, so feel free to pull up your notebook from the last class's studio.\n",
    "\n",
    "We will now be focusing our attention on a different region in the United States, the Northeast. When you open up the `dataset` folder, you will have 13 CSVs, including the San Francisco and Los Angeles data from the last lesson. The 13 CSVs are each a different terminal market in the United States.\n",
    "\n",
    "A **terminal market** is a central site, often in a metropolitan area, that serves as an assembly and trading place for commodities. Terminal markets for agricultural commodities are usually at or near major transportation hubs. [Definition Source](https://en.wikipedia.org/wiki/Terminal_market#:~:text=A%20terminal%20market%20is%20a,or%20near%20major%20transportation%20hubs)\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "Import the CSVs for each of the following cities: Baltimore, Boston, New York, and Philadelphia. Set up a dataframe for each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66c9a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and CSVs. Make some dataframes!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "baltimore = pd.read_csv(\"dataset/baltimore_9-24-2016_9-30-2017.csv\")\n",
    "boston = pd.read_csv(\"dataset/boston_9-24-2016_9-30-2017.csv\")\n",
    "new_york = pd.read_csv(\"dataset/new-york_9-24-2016_9-30-2017.csv\")\n",
    "philly = pd.read_csv(\"dataset/philadelphia_9-24-2016_9-30-2017.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfda42f",
   "metadata": {},
   "source": [
    "## Clean Your Data\n",
    "\n",
    "In the last lesson, we cleaned the data related to San Francisco. Pull up your notebook from the last lesson and use it as a reference to clean up these new dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0fc8944-0191-47aa-bac6-a63f5265b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 1%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 3%\n",
      "Origin District - 100%\n",
      "Item Size - 16%\n",
      "Color - 80%\n",
      "Environment - 100%\n",
      "Unit of Sale - 84%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in baltimore.columns:\n",
    "    pct_missing = np.mean(baltimore[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "619f101e-77bc-4916-9f3b-f869aec8b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 92%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 81%\n",
      "Item Size - 1%\n",
      "Color - 14%\n",
      "Environment - 100%\n",
      "Unit of Sale - 87%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in boston.columns:\n",
    "    pct_missing = np.mean(boston[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79b05d6c-7917-4517-a116-0fd2022d5ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 84%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 87%\n",
      "Item Size - 7%\n",
      "Color - 81%\n",
      "Environment - 100%\n",
      "Unit of Sale - 78%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in new_york.columns:\n",
    "    pct_missing = np.mean(new_york[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2aadd1f7-f8ea-4169-bfe5-eff6508490c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commodity Name - 0%\n",
      "City Name - 0%\n",
      "Type - 100%\n",
      "Package - 0%\n",
      "Variety - 0%\n",
      "Sub Variety - 79%\n",
      "Grade - 100%\n",
      "Date - 0%\n",
      "Low Price - 0%\n",
      "High Price - 0%\n",
      "Mostly Low - 0%\n",
      "Mostly High - 0%\n",
      "Origin - 0%\n",
      "Origin District - 100%\n",
      "Item Size - 21%\n",
      "Color - 100%\n",
      "Environment - 100%\n",
      "Unit of Sale - 81%\n",
      "Quality - 100%\n",
      "Condition - 100%\n",
      "Appearance - 100%\n",
      "Storage - 100%\n",
      "Crop - 100%\n",
      "Repack - 0%\n",
      "Trans Mode - 100%\n"
     ]
    }
   ],
   "source": [
    "for col in philly.columns:\n",
    "    pct_missing = np.mean(philly[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98abc290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Commodity Name  City Name  Type             Package      Variety  \\\n",
      "0         PUMPKINS  BALTIMORE   NaN        24 inch bins          NaN   \n",
      "1         PUMPKINS  BALTIMORE   NaN        24 inch bins          NaN   \n",
      "2         PUMPKINS  BALTIMORE   NaN        24 inch bins  HOWDEN TYPE   \n",
      "3         PUMPKINS  BALTIMORE   NaN        24 inch bins  HOWDEN TYPE   \n",
      "4         PUMPKINS  BALTIMORE   NaN        24 inch bins  HOWDEN TYPE   \n",
      "..             ...        ...   ...                 ...          ...   \n",
      "148       PUMPKINS  BALTIMORE   NaN  1/2 bushel cartons    MINIATURE   \n",
      "149       PUMPKINS  BALTIMORE   NaN  1/2 bushel cartons    MINIATURE   \n",
      "150       PUMPKINS  BALTIMORE   NaN  1/2 bushel cartons    MINIATURE   \n",
      "151       PUMPKINS  BALTIMORE   NaN  1/2 bushel cartons    MINIATURE   \n",
      "152       PUMPKINS  BALTIMORE   NaN  1/2 bushel cartons    MINIATURE   \n",
      "\n",
      "    Sub Variety  Grade        Date  Low Price  High Price  Mostly Low  \\\n",
      "0           NaN    NaN  04/29/2017        270       280.0         270   \n",
      "1           NaN    NaN  05/06/2017        270       280.0         270   \n",
      "2           NaN    NaN  09/24/2016        160       160.0         160   \n",
      "3           NaN    NaN  09/24/2016        160       160.0         160   \n",
      "4           NaN    NaN  11/05/2016         90       100.0          90   \n",
      "..          ...    ...         ...        ...         ...         ...   \n",
      "148         NaN    NaN  09/30/2017         18        18.0          18   \n",
      "149         NaN    NaN  09/30/2017         18        18.0          18   \n",
      "150  ROUND TYPE    NaN  09/24/2016         15        15.0          15   \n",
      "151  ROUND TYPE    NaN  10/01/2016         15        15.0          15   \n",
      "152  ROUND TYPE    NaN  10/08/2016         15        15.0          15   \n",
      "\n",
      "     Mostly High        Origin Item Size   Color Unit of Sale  Crop Repack  \\\n",
      "0          280.0           NaN       lge     NaN          NaN   NaN      E   \n",
      "1          280.0           NaN       lge     NaN          NaN   NaN      E   \n",
      "2          160.0      DELAWARE       med     NaN          NaN   NaN      N   \n",
      "3          160.0      VIRGINIA       med     NaN          NaN   NaN      N   \n",
      "4          100.0      MARYLAND       lge     NaN          NaN   NaN      N   \n",
      "..           ...           ...       ...     ...          ...   ...    ...   \n",
      "148         18.0      MARYLAND       NaN  ORANGE          NaN   NaN      N   \n",
      "149         18.0  PENNSYLVANIA       NaN  ORANGE          NaN   NaN      N   \n",
      "150         15.0      MARYLAND       sml     NaN          NaN   NaN      N   \n",
      "151         15.0      MARYLAND       sml     NaN          NaN   NaN      N   \n",
      "152         15.0      MARYLAND       sml     NaN          NaN   NaN      N   \n",
      "\n",
      "     Trans Mode  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4           NaN  \n",
      "..          ...  \n",
      "148         NaN  \n",
      "149         NaN  \n",
      "150         NaN  \n",
      "151         NaN  \n",
      "152         NaN  \n",
      "\n",
      "[153 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# Clean your data here!\n",
    "\n",
    "new_baltimore = baltimore.drop([\"Origin District\", \"Environment\", \"Quality\", \"Condition\", \"Appearance\", \"Storage\"], axis=1)\n",
    "\n",
    "print(new_baltimore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71ef5c26-73e2-4e55-bcc6-92a9a8be2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_boston = boston.drop([\"Origin District\", \"Environment\", \"Quality\", \"Condition\", \"Appearance\", \"Storage\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3692bdb-868a-4b63-a911-aa500770ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_york = new_york.drop([\"Origin District\", \"Environment\", \"Quality\", \"Condition\", \"Appearance\", \"Storage\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0606d1ad-839c-418a-99e7-fb3024038129",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_philly = philly.drop([\"Origin District\", \"Environment\", \"Quality\", \"Condition\", \"Appearance\", \"Storage\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b01b9",
   "metadata": {},
   "source": [
    "## Combine Your Data\n",
    "\n",
    "Now that you have four clean sets of data, combine all four into one dataframe that represents the entire Northeast region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da059f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 674 entries, 0 to 56\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Commodity Name  674 non-null    object \n",
      " 1   City Name       674 non-null    object \n",
      " 2   Type            0 non-null      float64\n",
      " 3   Package         674 non-null    object \n",
      " 4   Variety         672 non-null    object \n",
      " 5   Sub Variety     83 non-null     object \n",
      " 6   Grade           0 non-null      float64\n",
      " 7   Date            674 non-null    object \n",
      " 8   Low Price       674 non-null    int64  \n",
      " 9   High Price      674 non-null    float64\n",
      " 10  Mostly Low      674 non-null    int64  \n",
      " 11  Mostly High     674 non-null    float64\n",
      " 12  Origin          669 non-null    object \n",
      " 13  Item Size       625 non-null    object \n",
      " 14  Color           356 non-null    object \n",
      " 15  Unit of Sale    106 non-null    object \n",
      " 16  Crop            0 non-null      float64\n",
      " 17  Repack          674 non-null    object \n",
      " 18  Trans Mode      0 non-null      float64\n",
      "dtypes: float64(6), int64(2), object(11)\n",
      "memory usage: 105.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Combine the four dataframes into one!\n",
    "northeast_df = pd.concat([new_baltimore, new_boston, new_new_york, new_philly])\n",
    "print(northeast_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8590082f",
   "metadata": {},
   "source": [
    "## Answer Some Questions\n",
    "\n",
    "Use `groupby()` and `agg()` to answer the following two questions:\n",
    "\n",
    "1. What is the mean low and high prices for each type of **unit of sale** in the Northeast region? \n",
    "2. For each region, what is the average number of pumpkins per variety that came into terminal markets for the year? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c839639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Type  Grade   Low Price  High Price  Mostly Low  Mostly High  \\\n",
      "Unit of Sale                                                                 \n",
      "EACH           NaN    NaN   47.916667   59.166667   47.916667    59.166667   \n",
      "PER BIN        NaN    NaN  185.845070  206.619718  193.521127   204.859155   \n",
      "SHELLACKED     NaN    NaN   16.000000   17.545455   16.000000    17.545455   \n",
      "\n",
      "              Crop  Trans Mode  \n",
      "Unit of Sale                    \n",
      "EACH           NaN         NaN  \n",
      "PER BIN        NaN         NaN  \n",
      "SHELLACKED     NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the mean low and high prices in the Northeast region for each type of unit of sale.\n",
    "\n",
    "unit_group = northeast_df.groupby(\"Unit of Sale\")\n",
    "print(unit_group.agg(\"mean\", numeric_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4b23352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety\n",
      "HOWDEN TYPE                 56.00\n",
      "PIE TYPE                    49.50\n",
      "MINIATURE                   24.25\n",
      "BIG MACK TYPE               13.75\n",
      "CINDERELLA                   9.75\n",
      "FAIRYTALE                    9.25\n",
      "KNUCKLE HEAD                 2.25\n",
      "BLUE TYPE                    1.75\n",
      "MIXED HEIRLOOM VARIETIES     1.00\n",
      "HOWDEN WHITE TYPE            0.50\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Put your code here to find the average number of pumpkins coming into terminal markets of each variety.\n",
    "\n",
    "num_cities = len(northeast_df['City Name'].unique())\n",
    "print(northeast_df['Variety'].value_counts()/num_cities)\n",
    "\n",
    "# city_group = northeast_df.groupby(\"City Name\")\n",
    "# average_pumpkins = city_group[\"Variety\"].value_counts() / 4\n",
    "# print(average_pumpkins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5cff4",
   "metadata": {},
   "source": [
    "## Bonus Mission\n",
    "\n",
    "Try answering the same questions for the Midwest (Chicago, Detroit, and St. Louis) or the Southeast (Atlanta, Columbia, and Miami) regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d22b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the bonus mission if you have time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbc152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
